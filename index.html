<!DOCTYPE html>
<html lang="en-us">
  <head>
	<meta name="generator" content="Hugo 0.100.2" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Home | Jeremy Gillen</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
    </ul>
    <hr/>
    </nav>







<p><img src="/./_index_files/IMG_8254_square.JPG" style="max-width:25%;min-width:40px;float:right;padding:10px" alt="Photo of me" /></p>
<div id="jeremy-gillen" class="section level1">
<h1>Jeremy Gillen</h1>
<p>Hi. I recently finished an undergrad and honours year in CS and Neuroscience at UNSW. I’m interested in doing research on <a href="https://www.eacambridge.org/agi-week-2">AI Alignment</a>, to reduce the risk of things going badly when someone works out how to build smarter-than-human AI. I think research toward a better theoretical understand of learning algorithms and agents will reduce this risk.</p>
<p>I’m making this site to serve as a portfolio/resume type thing, even though I don’t have much to put on it yet. Hopefully it will motivate me to make things and do things.</p>
<div id="academic" class="section level2">
<h2>Academic</h2>
<ul>
<li>2021 Honours Thesis: <em>On the Algorithmic Hypothesis Class
Complexity of Deep Neural Networks</em> <a href="./thesis.pdf">[pdf]</a>
<ul>
<li>This project was an attempt to prove a generalisation bound on a two-layer neural network (under a lot of assumptions). The project was a success but the main result is fairly trivial. I learned a lot about current research on why neural networks generalize well despite being massively overparameterized.</li>
<li>Supervised by Dr Tongliang Liu in <a href="https://www.tmllab.ai/team">TML Lab</a></li>
<li>Achieved First Class Honours with mark of 89.</li>
</ul></li>
<li>2015 - 2020 Bachelor of Science (Neuroscience) / Bachelor of Computer Science (AI) at UNSW (Average Mark 80)</li>
</ul>
</div>
<div id="ml-and-alignment-related" class="section level2">
<h2>ML and alignment related</h2>
<ul>
<li><a href="https://www.serimats.org/">SERI MATS Scholar</a> in the Agent Foundations stream</li>
<li><a href="https://www.eacambridge.org/agi-safety-fundamentals">AGI Safety Fundamentals Course</a> - Final project was an <a href="https://www.lesswrong.com/posts/HtEffpHcLxppLN6dL/explaining-inner-alignment-to-myself">essay</a> on inner alignment</li>
<li>Summer 2021/22 - <a href="https://www.monash.edu/it/events/2021/international-school-in-artificial-intelligence-and-its-applications-in-computer-science-isaac">Summer School in AI at Monash</a></li>
<li>Summer 2021/22 - Sydney AI Safety fellowship</li>
<li>Worked through most ET Jaynes’ <a href="https://www.goodreads.com/book/show/151848.Probability_Theory">Probability Theory: The Logic of Science</a> and contributed some exercise solutions <a href="https://github.com/MaksimIM/JaynesProbabilityTheory">here</a></li>
<li>Various small machine learning projects: <a href="/old/">Random walk sampler demonstration</a>, <a href="https://github.com/jezgillen/coordinet/blob/main/Coordinate%20based%20discriminative%20image%20model%20report.pdf">CNN inductive bias</a>, <a href="https://github.com/jezgillen/baysian-neural-nets/blob/master/BayesNetworks.py">Bayesian Neural Networks</a>, <a href="https://github.com/jezgillen/CapsuleNet">Capsule network</a>, <a href="https://github.com/jezgillen/Tensorflow-Eager-Variational-Autoencoder">VAE</a>, <a href="https://github.com/jezgillen/double-descent-experiments">Double descent</a></li>
</ul>
</div>
<div id="lesswrong-posts" class="section level2">
<h2>LessWrong posts</h2>
<ul>
<li><a href="https://www.lesswrong.com/posts/e4SMfYWb4Tz568yh6/goodhart-s-law-causal-diagrams">Goodhart’s Law Causal Diagrams</a>: Writing up JustinShovelain’s ideas on Goodheart’s Law</li>
<li><a href="https://www.lesswrong.com/posts/HtEffpHcLxppLN6dL/explaining-inner-alignment-to-myself">Explaining inner alignment to myself</a>: Distillation of <a href="https://arxiv.org/abs/1906.01820">Risks from Learned Optimization</a></li>
</ul>
</div>
<div id="teaching" class="section level2">
<h2>Teaching</h2>
<ul>
<li>2020-2021: Tutoring and Admin for <a href="https://www.handbook.unsw.edu.au/postgraduate/courses/2019/COMP9418">COMP9418</a>. In this role I designed the second assignment (a competition to best model some artifically generated time series data), and was employed to rewrite all the tutorial code to make it cleaner, faster and object oriented. The tutorial code each week builds up a <a href="https://en.wikipedia.org/wiki/Graphical_model">PGM</a> library that the students then use in the assignments and final exam.
<ul>
<li>Student feedback for me can be found <a href="/student_feedback">here</a>.</li>
<li>I created a new tutorial on implementing <a href="https://github.com/UNSW-COMP9418/Week09/blob/main/COMP9418_W09_Gaussian_Factors.ipynb">Gaussian Bayes Nets</a> from scratch.</li>
</ul></li>
<li>2021: Tutoring for <a href="https://www.sydney.edu.au/units/COMP5328">COMP5328: Advanced Machine Learning</a></li>
<li>2019-2020: Academic Tutor at Shalom College</li>
<li>2019: Lab demonstrator for COMP2121 (Microprocessors and Interfacing)</li>
</ul>
</div>
<div id="links" class="section level2">
<h2>Links</h2>
<ul>
<li><a href="https://github.com/jezgillen">Github</a></li>
<li><a href="https://www.linkedin.com/in/jeremygillen/">LinkedIn</a></li>
</ul>
</div>
</div>




  <footer>
  <script defer src="//yihui.org/js/math-code.js"></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script defer src="//yihui.org/js/center-img.js"></script>

  
  </footer>
  </body>
</html>

